{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**CODE FLOW EXPLANATION**"
      ],
      "metadata": {
        "id": "9XSXuZ2DdxjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 1: Extract Data from the PDF**\n",
        "The first step involves extracting structured data from PDF files using the PDFDataExtraction class. This step is crucial for parsing and organizing raw data into meaningful structures.\n",
        "\n",
        "##Input:\n",
        "\n",
        "* The method `process_pdf()` in the PDFDataExtraction class takes a PDF file as input.\n",
        "\n",
        "##Processing:\n",
        "\n",
        "####1) Tables Extraction:\n",
        "* The `img2table` library is used to extract tabular data from the PDF.\n",
        "* The extracted tables are stored as objects in the output dictionary under the key `'tables'`.\n",
        "\n",
        "####2) Key-Value Pairs Extraction:\n",
        "\n",
        "\n",
        "* Regular expressions (regex) are employed to identify key-value pairs (non-tabular data) in the PDF.\n",
        "* These extracted key-value pairs are organized into a JSON-like structure and stored in the output dictionary under the key `'key_value_pairs'`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ITRiGiohhvsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 2: Convert Extracted Data into HTML**\n",
        "Once the data is extracted, it is converted into an HTML format for further processing or display.\n",
        "\n",
        "#Input:\n",
        "\n",
        "The output from `process_pdf()` (a dictionary containing 'tables' and\n",
        "'key_value_pairs').\n",
        "#Processing:\n",
        "\n",
        "The `combine_html()` method performs the following operations:\n",
        "####Extract HTML from Table Objects:\n",
        "\n",
        "\n",
        "* Iterates through the `'tables'` data.\n",
        "* For each table object, calls its .html property or method to generate its HTML representation.\n",
        "* Appends all table HTML strings into a single combined HTML structure.\n",
        "\n",
        "\n",
        "\n",
        "####Convert JSON to HTML:\n",
        "\n",
        "\n",
        "* Converts the `'key_value_pairs'` JSON data into an HTML table using the helper function `json_to_html_table`.\n",
        "* Appends the generated HTML to the combined HTML structure.\n",
        "* The resulting HTML contains both tabular and key-value data, merged into a single string.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JFS9qyTFixn-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 3: Compare PDF Data Using LLM**\n",
        "The final step involves leveraging a Large Language Model (LLM) to perform data comparison between two PDFs.\n",
        "\n",
        "#Input:\n",
        "\n",
        "The HTML data generated from Step 2 for both PDF files:\n",
        "\n",
        "* **Datasheet**: HTML data for the first PDF file.\n",
        "\n",
        "* **Vendor**: HTML data for the second PDF file.\n",
        "\n",
        "#Processing:\n",
        "\n",
        "Both HTML datasets are fed into an LLM model designed to analyze and compare data.\n",
        "The model compares the content of the two PDFs based on specific parameters and tags, such as:\n",
        "*   Key-value pairs\n",
        "*   Tables and their structure\n",
        "* Alignment of content between the two documents.\n",
        "\n",
        "The comparison is done at a semantic level, leveraging the modelâ€™s ability to identify relationships and patterns in the data.\n",
        "#Output:\n",
        "\n",
        "The model returns a structured result indicating the comparison outcome. This could include:\n",
        "* Matching or mismatched parameters between the two documents.\n",
        "* Tag-by-tag or parameter-level comparison details."
      ],
      "metadata": {
        "id": "nQre4mbskhVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aENKjo9gsvm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8f262c2c-62b5-47cb-df0b-e643ad79e530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr-eng is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tesseract-ocr\n",
        "!apt-get install tesseract-ocr-eng"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install opencv-contrib-python-headless"
      ],
      "metadata": {
        "id": "1xHNwyxhJHG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "069f79c8-a366-4219-a9cd-0bc9dfc37568"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python-headless) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install img2table gradio"
      ],
      "metadata": {
        "id": "NlbsvK3AJHJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c37dae10-fa7d-43f9-a403-d7ed25227b04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: img2table in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
            "Requirement already satisfied: polars>=1.2 in /usr/local/lib/python3.10/dist-packages (from polars[pandas]>=1.2->img2table) (1.9.0)\n",
            "Requirement already satisfied: pyarrow>=7 in /usr/local/lib/python3.10/dist-packages (from img2table) (17.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from img2table) (1.26.4)\n",
            "Requirement already satisfied: pypdfium2 in /usr/local/lib/python3.10/dist-packages (from img2table) (4.30.0)\n",
            "Requirement already satisfied: opencv-contrib-python>=4 in /usr/local/lib/python3.10/dist-packages (from img2table) (4.10.0.84)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from img2table) (0.60.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from img2table) (4.12.3)\n",
            "Requirement already satisfied: xlsxwriter>=3.0.6 in /usr/local/lib/python3.10/dist-packages (from img2table) (3.2.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->img2table) (2.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->img2table) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required packages:\n",
        "!pip install pdfplumber pandas pytesseract opencv-python numpy chromadb"
      ],
      "metadata": {
        "id": "VgoroLQwJHPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "e244cd35-93d1-4b32-a4ff-7686b148d357"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.23)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.32.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.7.4)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-proto==1.28.2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.49b2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.26.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraies"
      ],
      "metadata": {
        "id": "Qvqs_BLzkkqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Union\n",
        "import logging\n",
        "import json\n",
        "from huggingface_hub import InferenceClient\n",
        "from google.colab import userdata\n",
        "import chromadb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from img2table.document import Image, PDF\n",
        "from img2table.ocr import TesseractOCR\n",
        "import pandas as pd\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "iAEogUBUMF0a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFDataExtractor:\n",
        "    \"\"\"Main class for extracting data from PDFs with tables and key-value pairs.\"\"\"\n",
        "\n",
        "    def __init__(self, config_path: str = None):\n",
        "        \"\"\"Initialize the extractor with optional configuration.\"\"\"\n",
        "        self.logger = self._setup_logging()\n",
        "        self.config = self._load_config(config_path) if config_path else {}\n",
        "\n",
        "    def _setup_logging(self) -> logging.Logger:\n",
        "        \"\"\"Configure logging for the extraction process.\"\"\"\n",
        "        logger = logging.getLogger('PDFDataExtractor')\n",
        "        logger.setLevel(logging.INFO)\n",
        "        handler = logging.StreamHandler()\n",
        "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "        handler.setFormatter(formatter)\n",
        "        logger.addHandler(handler)\n",
        "        return logger\n",
        "\n",
        "    def _load_config(self, config_path: str) -> Dict:\n",
        "        \"\"\"Load configuration from JSON file.\"\"\"\n",
        "        with open(config_path, 'r') as f:\n",
        "            return json.load(f)\n",
        "\n",
        "    def extract_tables_PDFPlumber(self, pdf_path: str) -> List[pd.DataFrame]:\n",
        "        \"\"\"Extract tables from PDF using pdfplumber.\"\"\"\n",
        "        tables = []\n",
        "        self.logger.info(f\"Processing PDF: {pdf_path}\")\n",
        "\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page_num, page in enumerate(pdf.pages, 1):\n",
        "                    # Extract tables from the page\n",
        "                    page_tables = page.extract_tables()\n",
        "\n",
        "                    for table_num, table in enumerate(page_tables, 1):\n",
        "                        if table:\n",
        "                            # Convert to DataFrame and clean up\n",
        "                            df = pd.DataFrame(table[1:], columns=table[0])\n",
        "                            df = self._clean_dataframe(df)\n",
        "                            tables.append(df)\n",
        "\n",
        "                            self.logger.info(f\"Extracted table {table_num} from page {page_num}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error extracting tables: {str(e)}\")\n",
        "\n",
        "        return tables\n",
        "\n",
        "    def extract_tables_img2table(self,pdf_path:str):\n",
        "      \"\"\"Extract tables from PDF using img2table.\"\"\"\n",
        "      tables = []\n",
        "      pdf = PDF(src=pdf_path)\n",
        "      ocr= TesseractOCR(lang='eng')\n",
        "      tables= pdf.extract_tables(ocr=ocr,min_confidence=70)\n",
        "      return tables\n",
        "\n",
        "    def extract_key_value_pairs(self, pdf_path: str) -> Dict[str, str]:\n",
        "        \"\"\"Extract key-value pairs using pattern matching and positioning.\"\"\"\n",
        "        key_value_pairs = {}\n",
        "\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    text = page.extract_text()\n",
        "\n",
        "                    # Extract using common patterns\n",
        "                    pairs = self._pattern_based_extraction(text)\n",
        "                    key_value_pairs.update(pairs)\n",
        "\n",
        "                    # Extract using positionin(tables extraction by matching lines)\n",
        "                    # positioned_pairs = self._position_based_extraction(page)\n",
        "                    # key_value_pairs.update(positioned_pairs)\n",
        "                    # print(f\"positioned pair: {positioned_pairs}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error extracting key-value pairs: {str(e)}\")\n",
        "\n",
        "        return key_value_pairs\n",
        "\n",
        "    def _pattern_based_extraction(self, text: str,patterns:List=[r'([^:\\n]+):\\s*([^\\n]+)',r'([^=\\n]+)=\\s*([^\\n]+)',r'([^\\t\\n]+)\\t+([^\\n]+)']) -> Dict[str, str]:\n",
        "        \"\"\"Extract key-value pairs using regex patterns.\"\"\"\n",
        "        pairs = {}\n",
        "\n",
        "        # Common patterns for key-value pairs\n",
        "        # patterns = [\n",
        "        #     r'([^:\\n]+):\\s*([^\\n]+)',  # Basic pattern: \"Key: Value\"\n",
        "        #     r'([^=\\n]+)=\\s*([^\\n]+)',  # Alternative pattern: \"Key = Value\"\n",
        "        #     r'([^\\t\\n]+)\\t+([^\\n]+)'   # Tab-separated pattern\n",
        "        # ]\n",
        "\n",
        "        for pattern in patterns:\n",
        "            import re\n",
        "            matches = re.findall(pattern, text)\n",
        "            for key, value in matches:\n",
        "                key = key.strip()\n",
        "                value = value.strip()\n",
        "                if key and value:\n",
        "                    pairs[key] = value\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    def _position_based_extraction(self, page) -> Dict[str, str]:\n",
        "        \"\"\"Extract key-value pairs based on positioning in the document.\"\"\"\n",
        "        pairs = {}\n",
        "\n",
        "        # Extract words with their positions\n",
        "        words = page.extract_words()\n",
        "\n",
        "        # Group words by their vertical position (assuming keys and values are on the same line)\n",
        "        lines = {}\n",
        "        for word in words:\n",
        "            y_pos = round(word['top'])\n",
        "            if y_pos not in lines:\n",
        "                lines[y_pos] = []\n",
        "            lines[y_pos].append(word)\n",
        "\n",
        "        # Analyze each line for potential key-value pairs\n",
        "        for y_pos, line_words in lines.items():\n",
        "            if len(line_words) >= 2:\n",
        "                # Assume first word(s) are key and last word(s) are value\n",
        "                potential_key = ' '.join(w['text'] for w in line_words[:len(line_words)//2])\n",
        "                potential_value = ' '.join(w['text'] for w in line_words[len(line_words)//2:])\n",
        "\n",
        "                if potential_key and potential_value:\n",
        "                    pairs[potential_key.strip()] = potential_value.strip()\n",
        "\n",
        "        return pairs\n",
        "\n",
        "    def _clean_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Clean and preprocess extracted DataFrame.\"\"\"\n",
        "        # Remove empty rows and columns\n",
        "        df = df.dropna(how='all').dropna(axis=1, how='all')\n",
        "\n",
        "        # Strip whitespace from strings\n",
        "        df = df.apply(lambda x: x.str.strip() if isinstance(x, str) else x)\n",
        "\n",
        "        # Remove duplicate rows\n",
        "        df = df.drop_duplicates()\n",
        "\n",
        "        return df\n",
        "\n",
        "    def process_pdf(self, pdf_path: str) -> Dict[str, Union[List[pd.DataFrame], Dict[str, str]]]:\n",
        "        \"\"\"Process PDF and extract both tables and key-value pairs.\"\"\"\n",
        "        result = {\n",
        "            'tables': self.extract_tables_img2table(pdf_path),\n",
        "            'key_value_pairs': self.extract_key_value_pairs(pdf_path)\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def json_to_html_table(self,json_data):\n",
        "        \"\"\"\n",
        "        Converts data from a JSON file into an HTML table.\n",
        "\n",
        "        Args:\n",
        "            json_file_path (str): Path to the JSON file.\n",
        "\n",
        "        Returns:\n",
        "            str: HTML string representing the data in a table format.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # logging.info(f\"Loading JSON data from {json_file_path}.\")\n",
        "            # with open(json_file_path, 'r') as file:\n",
        "            #     json_data = json.load(file)\n",
        "\n",
        "            logging.debug(\"Generating HTML table from JSON data.\")\n",
        "            html_table = \"<table border='1' style='border-collapse: collapse; width: 100%;'>\"\n",
        "            html_table += \"<tr><th>Key</th><th>Value</th></tr>\"\n",
        "\n",
        "            for key, value in json_data.items():\n",
        "                html_table += f\"<tr><td>{key}</td><td>{value}</td></tr>\"\n",
        "\n",
        "            html_table += \"</table>\"\n",
        "            logging.info(\"HTML table generated successfully.\")\n",
        "            return html_table\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error while converting JSON to HTML table: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    def combine_html(self,pdf_data):\n",
        "         \"\"\"\n",
        "          Combines multiple HTML strings into a single string.\n",
        "\n",
        "         Args:\n",
        "            pdf_data (dict): A dictionary containing data extracted from a PDF,\n",
        "                         including tables and key-value pairs.\n",
        "\n",
        "            Expected structure of `pdf_data`:\n",
        "            {\n",
        "                'tables': [[table1, table2, ...], [table3, table4, ...], ...],\n",
        "                'key_value_pairs': {...}\n",
        "            }\n",
        "\n",
        "         Returns:\n",
        "           str: A single combined HTML string containing all tables and key-value pairs.\n",
        "         \"\"\"\n",
        "         combined_html = \"\"\n",
        "         # Add key-value pairs converted to HTML\n",
        "         combined_html += f\"\\n {self.json_to_html_table(pdf_data.get('key_value_pairs', {}))}\"\n",
        "\n",
        "         # Iterate over the tables in pdf_data\n",
        "         for i in range(len(pdf_data['tables'])):\n",
        "           for j in range(len(pdf_data['tables'][i])):\n",
        "              combined_html = combined_html + f\"\\n {pdf_data['tables'][i][j].html}\"\n",
        "\n",
        "         return combined_html\n",
        "\n",
        "\n",
        "    def save_results(self, results: Dict, output_dir: str):\n",
        "        \"\"\"Save extracted data to files.\"\"\"\n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Save tables to Excel sheets\n",
        "        if isinstance(results['tables'],list):\n",
        "            with pd.ExcelWriter(output_path / 'extracted_tables.xlsx') as writer:\n",
        "                for i, df in enumerate(results['tables'], 1):\n",
        "                    df.to_excel(writer, sheet_name=f'Table_{i}', index=False)\n",
        "\n",
        "        # Save key-value pairs to JSON\n",
        "        if results['key_value_pairs']:\n",
        "            with open(output_path / 'key_value_pairs.json', 'w') as f:\n",
        "                json.dump(results['key_value_pairs'], f, indent=4)\n",
        "\n"
      ],
      "metadata": {
        "id": "kZJE9adiMF6E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class pdf_data_comparison:\n",
        "    def __init__(self, hf_api_key):\n",
        "        \"\"\"\n",
        "        Initializes the HTMLTableProcessor class and sets up logging configuration.\n",
        "        \"\"\"\n",
        "        self.setup_logging()\n",
        "        self.client = InferenceClient(api_key=hf_api_key)\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"\n",
        "        Sets up logging configuration for the class.\n",
        "        \"\"\"\n",
        "        logging.basicConfig(\n",
        "            level=logging.DEBUG,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler(\"html_table_processor.log\"),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "        logging.info(\"Logging configuration set up successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compare_html_data(self, datasheet_html, vendor_html,model_name: str=\"Qwen/Qwen2.5-72B-Instruct\",query= None):\n",
        "        \"\"\"\n",
        "        Compares the data between two HTML contents based on given parameters.\n",
        "\n",
        "        Args:\n",
        "            datasheet_html (str): HTML content of the datasheet.\n",
        "            vendor_html (str): HTML content of the vendor's data.\n",
        "            parameters (list): List of parameters to compare.\n",
        "\n",
        "        Returns:\n",
        "            str: Comparison result as generated by the InferenceClient.\n",
        "        \"\"\"\n",
        "        if query != None:\n",
        "            prompt = f\"\"\"\n",
        "               Compare the data extracted from the following HTML contents:\n",
        "\n",
        "               **Datasheet HTML**:\n",
        "               {datasheet_html}\n",
        "\n",
        "               **Vendor HTML**:\n",
        "               {vendor_html}\n",
        "\n",
        "               {query}\n",
        "               \"\"\"\n",
        "        else:\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            Compare the data extracted from the following HTML contents:\n",
        "\n",
        "            **Datasheet html**:\n",
        "            ```{datasheet_html}```\n",
        "\n",
        "            **Vendor html**:\n",
        "            ```{vendor_html}```\n",
        "\n",
        "            compare all the parameter values in both the html contents.\n",
        "            when there is table with multiple column try to extract and compare the individual rows.\n",
        "            If there are multiple tables compare it individually.\n",
        "\n",
        "            Output Instructions:\n",
        "            - Present the results in a clear tabular format with columns for:\n",
        "            1. **Parameter** (parameter name)\n",
        "            2. **Datasheet Value**\n",
        "            3. **Vendor Value**\n",
        "            4. **Result** (Matching, Discrepancy, Missing)\n",
        "            5. **Detailed Explanation**\n",
        "            - Include comprehensive details for any discrepancies or missing entries.\n",
        "            give the result with separate table heading parameter comparison and Tag Number comparison.\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are an Expert data analyst who can analyse HTML documents.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        # Generate response using the InferenceClient\n",
        "        stream = self.client.chat.completions.create(\n",
        "            model= model_name,\n",
        "            messages=messages,\n",
        "            max_tokens=5000,\n",
        "            stream=True,\n",
        "            temperature=1,\n",
        "            top_p=0.1\n",
        "\n",
        "        )\n",
        "\n",
        "        result = \"\"\n",
        "        for chunk in stream:\n",
        "            result += chunk.choices[0].delta.content\n",
        "\n",
        "        return result\n",
        "    def convert_into_dataframe(self, input_data):\n",
        "        \"\"\"\n",
        "        Extracts a table from a string and converts it into a DataFrame.\n",
        "\n",
        "        Args:\n",
        "            input_string (str): The string containing table-like data.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame representation of the table.\n",
        "        \"\"\"\n",
        "        # Split the input string into lines\n",
        "        lines = input_data.split(\"\\n\")\n",
        "\n",
        "        # Filter only rows that are part of the table (lines with | separators)\n",
        "        table_rows = [line for line in lines if '|' in line]\n",
        "\n",
        "        # Remove separator rows (lines with only '-' or '|' characters)\n",
        "        table_rows = [row for row in table_rows if not re.match(r'^\\|[-\\s]*\\|$', row)]\n",
        "\n",
        "        # Split each row into columns using | as a separator\n",
        "        table_data = [row.split('|')[1:-1] for row in table_rows]  # Exclude first and last empty entries\n",
        "\n",
        "        # Strip whitespace from each cell\n",
        "        table_data = [[cell.strip() for cell in row] for row in table_data]\n",
        "\n",
        "        # Use the first row as the header\n",
        "        header = table_data[0]\n",
        "        data = table_data[1:]\n",
        "\n",
        "        # Create a DataFrame\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "        # Remove any symbol characters from the DataFrame\n",
        "        df = df.replace(r'[^\\w\\s]', '', regex=True)\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "J7dmLmdJe31P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def process_pdf_data(pdf):\n",
        "   # Initialize extractor\n",
        "   extractor = PDFDataExtractor()\n",
        "   extractor._setup_logging()\n",
        "\n",
        "   # Process Datasheet PDF\n",
        "   results = extractor.process_pdf(pdf)\n",
        "   html_data = extractor.combine_html(results)\n",
        "\n",
        "   return html_data\n",
        "\n",
        "def compare_pdfs(result1,result2):\n",
        "    # Example comparison logic: Replace this with your actual comparison logic\n",
        "\n",
        "    table_comparison = pdf_data_comparison(hf_api_key=userdata.get('HF_TOKEN'))\n",
        "    comparison_result = table_comparison.compare_html_data(result1,result2)\n",
        "    output_path = \"comparison_result.md\"\n",
        "    with open(output_path, \"w\") as md_file:\n",
        "        md_file.write(comparison_result)\n",
        "    return comparison_result, output_path\n",
        "\n",
        "\n",
        "\n",
        "# Backend function for Gradio\n",
        "def process_and_compare(pdf1, pdf2):\n",
        "    result1 = process_pdf_data(pdf1)\n",
        "    result2 = process_pdf_data(pdf2)\n",
        "    comparison_result,output_path = compare_pdfs(result1,result2)\n",
        "\n",
        "    return comparison_result,output_path\n",
        "\n",
        "\n",
        "# Function to process the dropdown selection and return the initial less data text\n",
        "def get_initial_text(selected_option):\n",
        "    if selected_option == \"First PDF Data\":\n",
        "        return \"This is less text for the First PDF Data.\"\n",
        "    elif selected_option == \"Second PDF Data\":\n",
        "        return \"This is less text for the Second PDF Data.\"\n",
        "    else:\n",
        "        return \"Please select an option.\"\n",
        "\n",
        "# Function to toggle between full and short versions of the text\n",
        "def toggle_text(selected_option,pdf1,pdf2,current_state):\n",
        "    if selected_option == \"First PDF Data\":\n",
        "        if current_state == \"show_less\":\n",
        "            return (\n",
        "                process_pdf_data(pdf1),\n",
        "                \"Show Less\",\n",
        "                \"show_more\"\n",
        "            )\n",
        "        else:\n",
        "            return (\n",
        "                \"This is less text for the First PDF Data.\",\n",
        "                \"Show More\",\n",
        "                \"show_less\"\n",
        "            )\n",
        "    elif selected_option == \"Second PDF Data\":\n",
        "        if current_state == \"show_less\":\n",
        "            return (\n",
        "                process_pdf_data(pdf2),\n",
        "                \"Show Less\",\n",
        "                \"show_more\"\n",
        "            )\n",
        "        else:\n",
        "            return (\n",
        "                \"This is less text for the Second PDF Data.\",\n",
        "                \"Show More\",\n",
        "                \"show_less\"\n",
        "            )\n",
        "    else:\n",
        "        return \"Please select an option.\", \"Show More\", \"show_less\"\n",
        "\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# PDF Comparison Tool\")\n",
        "\n",
        "    with gr.Row():\n",
        "        pdf1_input = gr.File(label=\"Upload First PDF\", file_types=[\".pdf\"])\n",
        "        pdf2_input = gr.File(label=\"Upload Second PDF\", file_types=[\".pdf\"])\n",
        "\n",
        "    # flag =1\n",
        "    # if flag:\n",
        "    #    with gr.Row():\n",
        "    #        #patterns = gr.Textbox(label=\"PDF Patterns\",placeholder=\"[r'([^:\\n]+):\\s*([^\\n]+)',r'([^=\\n]+)=\\s*([^\\n]+)',r'([^\\t\\n]+)\\t+([^\\n]+)']\")\n",
        "    #        model_name = gr.Textbox(label=\"Model Name\",placeholder=\"Qwen/Qwen2.5-72B-Instruct\")\n",
        "    #        query = gr.Textbox(label=\"Query\")\n",
        "\n",
        "    gr.Markdown(\"# Extracted Data\")\n",
        "    with gr.Row():\n",
        "\n",
        "       dropdown = gr.Dropdown(\n",
        "            choices=[\"First PDF Data\", \"Second PDF Data\"],\n",
        "            label=\"Select Data to View\"\n",
        "        )\n",
        "\n",
        "    # Initial state to keep track of whether the text is wrapped down or up\n",
        "    text_state = gr.State(\"show_less\")  # Initial state is \"show_less\"\n",
        "\n",
        "    # Textbox to display the text data\n",
        "    text_display = gr.HTML()\n",
        "\n",
        "    # Button to toggle between Wrap Down and Wrap Up\n",
        "    toggle_button = gr.Button(\"Show More\")\n",
        "\n",
        "    gr.Markdown(\"# Comparison Result\")\n",
        "    compare_button = gr.Button(\"Process and Compare PDFs\")\n",
        "    result_output = gr.Markdown(label=\"Comparison Result\")\n",
        "    download_button = gr.File(label=\"Download Result md\")\n",
        "\n",
        "\n",
        "    # Event: Update text display when dropdown changes\n",
        "    dropdown.change(\n",
        "        fn=get_initial_text,\n",
        "        inputs=[dropdown],\n",
        "        outputs=[text_display]\n",
        "    )\n",
        "\n",
        "    # Event: Toggle between full and short text\n",
        "    toggle_button.click(\n",
        "        fn=toggle_text,\n",
        "        inputs=[dropdown,pdf1_input,pdf2_input,text_state],\n",
        "        outputs=[text_display, toggle_button, text_state]\n",
        "    )\n",
        "\n",
        "    compare_button.click(\n",
        "        fn=process_and_compare,\n",
        "        inputs=[pdf1_input, pdf2_input],\n",
        "        outputs=[result_output, download_button]\n",
        "    )\n",
        "\n",
        "\n",
        "# Launch the app\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "IQM9QIKKoDvF",
        "outputId": "e4e26e10-f143-4dd7-a526-64efca99cb66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://890b6a504bc8a84c1c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://890b6a504bc8a84c1c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QB5_hPFs6WW9"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}